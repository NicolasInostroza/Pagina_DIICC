<!-- templatemo 372 titanium -->
<!-- 
Titanium Template 
http://www.templatemo.com/preview/templatemo_372_titanium 
-->
<!--<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"> -->
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>Vladimir Riffo - Publications: Journals</title>
<meta name="keywords" content="" />
<meta name="description" content="" />
<link href="templatemo_style.css" rel="stylesheet" type="text/css" />

<link rel="stylesheet" href="css/orman.css" type="text/css" media="screen" />
<link rel="stylesheet" href="css/nivo-slider.css" type="text/css" media="screen" />	

<link rel="stylesheet" type="text/css" href="css/ddsmoothmenu.css" />
<LINK rel="SHORTCUT ICON" href="images/icon_vriffo.jpg">
<script type="text/javascript" src="js/jquery.min.js"></script>
<script type="text/javascript" src="js/ddsmoothmenu.js">
/***********************************************
* Smooth Navigational Menu- (c) Dynamic Drive DHTML code library (www.dynamicdrive.com)
* This notice MUST stay intact for legal use
* Visit Dynamic Drive at http://www.dynamicdrive.com/ for full source code
***********************************************/

</script>

<script language="javascript" type="text/javascript">

ddsmoothmenu.init({
	mainmenuid: "templatemo_menu", //menu DIV id
	orientation: 'h', //Horizontal or vertical menu: Set to "h" or "v"
	classname: 'ddsmoothmenu', //class added to menu's outer DIV
	//customtheme: ["#1c5a80", "#18374a"],
	contentsource: "markup" //"markup" or ["container_id", "path_to_menu_file"]
})

function clearText(field)
{
    if (field.defaultValue == field.value) field.value = '';
    else if (field.value == '') field.value = field.defaultValue;
}
</script>

<link rel="stylesheet" href="css/slimbox2.css" type="text/css" media="screen" /> 
<script type="text/JavaScript" src="js/slimbox2.js"></script> 
<!--  t e m p l a t e m o  372  t i t a n i u m  -->
</head>
<body>

<div id="templatemo_wrapper">
	<div id="templatemo_header">
    	<!--<div id="site_title"><a href="#">Titanium</a></div> -->
        
    <div class="half left" style="width:500px;">
        <br>
        <p><FONT COLOR=FFFFFF SIZE="6">VLADIMIR RIFFO</FONT></FONT></p>
        <p><FONT COLOR=D8D8D8 SIZE="2">Ph.D. in Engineering Sciences, Mention in Computer Science</FONT></FONT></p> 
    </div>
<!--    
    <div class="half right">
        <br>
        <p><FONT COLOR=FFFFFF SIZE="2">Ph.D. in Engineering Sciences, Mention in Computer Science</FONT></FONT></p>
    </div>  
-->           
        
<!--        <div id="templatemo_search">
            <form action="#" method="get">
              <input type="text" value="Search..." name="keyword" id="keyword" title="keyword" 
              				onfocus="clearText(this)" onblur="clearText(this)" class="txt_field" />
              <input type="submit" name="Search" value="" alt="Search" id="searchbutton" title="Search" class="sub_btn"  />
            </form>
        </div> -->
               
    </div><!-- END of templatemo_header -->
    
    <div id="templatemo_menu" class="ddsmoothmenu">
        <ul>
            <li><a href="index.html">Home</a></li>
            <li><a href="aboutme.html">About me</a></li>
            <li><a href="#">Publications</a>
                <ul>
                    <li><a href="">Journals</a>
                        <ul>
                            <li><a href="journals_WoS.html">WoS</a></li>
                            <li><a href="journals_SciELO.html">SciELO</a></li>
                        </ul>
                    </li>
                    <li><a href="conferences.html">Conferences</a></li>
              	</ul>
            </li>
            <!--<li><a href="blog.html">Teaching</a></li> -->
            <li><a href="contact.html">Contact</a></li>
        </ul>
        <br style="clear: left" />
    </div> <!-- end of templatemo_menu -->
<!--&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& -->
    
    <div id="templatemo_main">
    <h2>WoS Journals: Science Citation Index Expanded (SCI-EXPANDED)</h2>    
    <div class="post" style="border-bottom-color:#CCC;"></div>
    
<!--&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& -->    
<!--&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& -->    
      <div class="half left"style="width:315; margin-bottom:0;">
            
                <div class="Image_Frame" style="margin-bottom:20;">
                    <img style="border:1px solid #CCC;" src="Publications\Journals\Images\Neural_Network.png" alt="Geometric Model" width="315" height="auto" >
                </div>
                
                <a style="font-size:14px;"href="https://www.springer.com/journal/11837";>JOM, The Journal of The Minerals, Metals & Materials Society (TMS)</a>
        <p>Publisher: Springer</p>
                
          <p>Authors:<br>
          <strong>V. Riffo</strong>, and A. Pulgar</p>
          
          <!--<a href="#" class="more">DETAIL</a> -->
        </div>    	
      
      
        <div class="half right" style="width:615; margin-bottom:0;>
                   
		<div class="post">
		  <p><FONT SIZE="3">Predictive Model of the Percentage of Copper in the Matte
of the Teniente Converter Through an Artificial Neural Network</FONT></p>
                
                <p ALIGN="justify"><strong>Abstract:</strong> The Teniente converter is the main fusion equipment of the Hern√°n Videla Lira Foundry, in which matte, slag and gases are produced. The matte produced in the smelting process of copper concentrates in the Teniente converter contains variable percentages of copper. The expected range of copper in the matte varies from 74% to 76%. It is important to obtain these percentages of copper in the matte, since the copper that is not obtained is lost in the slag. In this work, we propose a predictive model with an artificial neural network to predict the percentage of copper that will be obtained in the matte produced in the converter so that the prediction allows modifying the different variables involved in advance. The results obtained are promising and present a mean-squared error of 0.1004 and an adequacy index of 0.9 for 140 test data.</p>
                                
                <div class="clear h20"></div>
                
                <div class="post_meta" style="margin-bottom:0";>
                	<span>Jan. 2022</span><span>DOI: <a href="https://link.springer.com/article/10.1007/s11837-021-05052-8">10.1007/s11837-021-05052-8</a></span><span><a href="https://rdcu.be/cEXMo">PDF</a></span><span><a href="Publications\Journals\BibTex\Riffo2022_JOM.txt">BibTeX</a></span><span>Published version: <a href="contact.html">Contact me</a></span><div class="clear"></div>
				</div>
        <!-- <a href="blog_post.html" class="more">More</a> -->
		
       </div>
       <div class="post" style="border-bottom-color:#CCC;"></div>        
<!--&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& -->    
<!--&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& -->    
      <div class="half left"style="width:315; margin-bottom:0;">
            
                <div class="Image_Frame" style="margin-bottom:20;">
                    <img style="border:1px solid #CCC;" src="Publications\Journals\Images\3D_Xray.png" alt="Geometric Model" width="315" height="auto" >
                </div>
                
                <a style="font-size:14px;"href="https://link.springer.com/journal/10921";>Journal Of Nondestructive Evaluation</a>
        <p>Publisher: Springer</p>
                
          <p>Authors:<br>
          <strong>V. Riffo</strong>, I. Godoy, and D. Mery</p>
          
          <!--<a href="#" class="more">DETAIL</a> -->
        </div>    	
      
      
        <div class="half right" style="width:615; margin-bottom:0;>
                   
		<div class="post">
		  <p><FONT SIZE="3">Handgun Detection in Single-Spectrum Multiple X-ray Views Based on
3D Object Recognition</FONT></p>
                
                <p ALIGN="justify"><strong>Abstract:</strong> In the last years, many computer vision algorithms have been proposed for baggage inspection using X-ray images. In these approaches, the idea is to detect automatically threat objects. In baggage inspection, however, a single view is insufficient because there could be occluded parts or intricate projections that cannot be observed with a single view. In order to avoid a misinterpretation based on a single view, we propose the use of single-spectrummultiple X-ray views. Our approach computes a 3D reconstruction using Space Carving, a method that reconstructs a 3D object from its 2D silhouettes (that have been segmented using Geodesic Active Contours). The detection is performed by analyzing 3D features (obtained from the 3D reconstruction). Instead of dual-energy, that is typically used in baggage inspection to analyze thematerial of the reconstructed objects, we propose simply to use a single-spectrum X-ray system for the detection of threat objects that can be recognized by analyzing the shape, such as handguns. The approach has been successfully tested on X-ray images of travel-bags that contain handguns. In the evaluation of our method, we have used sequences of X-ray images for the 3D reconstruction of objects inside travel-bags, where each sequence consists of 90 X-ray images, we obtained 0.97 in both recall and precision. We strongly believe that it is possible to design an automated aid for the human inspection task using these computer vision algorithms.</p>
                <div class="clear h20"></div>
                
                <div class="post_meta" style="margin-bottom:0";>
                <span>Download <a href="https://www.dropbox.com/sh/ff0tw8j9xcatndm/AABX76m17gRZpmKWRtNndTXma?dl=0">Example Code</a></span>
                </div>
                <div class="clear h20"></div>
                
                <div class="post_meta" style="margin-bottom:0";>
                	<span>Jul. 2019</span><span>DOI: <a href="https://link.springer.com/article/10.1007/s10921-019-0602-9">10.1007/s10921-019-0602-9</a></span><span><a href="Publications\Journals\PDF\Riffo2019_Springer_JNE.pdf">PDF</a></span><span><a href="Publications\Journals\BibTex\Riffo2019_Springer_JNE.txt">BibTeX</a></span><span>Published version: <a href="contact.html">Contact me</a></span><div class="clear"></div>
				</div>
        <!-- <a href="blog_post.html" class="more">More</a> -->
		
       </div>
       <div class="post" style="border-bottom-color:#CCC;"></div>    
<!--&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& -->    
<!--&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& -->    
      <div class="half left"style="width:315; margin-bottom:0;">
            
                <div class="Image_Frame" style="margin-bottom:20;">
                    <img style="border:1px solid #CCC;" src="Publications\Journals\Images\GeometricModel.png" alt="Geometric Model" width="315" height="auto" >
                </div>
                
                <a style="font-size:14px;"href="https://link.springer.com/journal/10921";>Journal Of Nondestructive Evaluation</a>
        <p>Publisher: Springer</p>
                
          <p>Authors:<br>
          <strong>V. Riffo</strong>, S. Flores, and D. Mery</p>
          
          <!--<a href="#" class="more">DETAIL</a> -->
        </div>    	
      
      
        <div class="half right" style="width:615; margin-bottom:0;>
                   
		<div class="post">
		  <p><FONT SIZE="3">Threat Objects Detection in X-Ray Images Using an Active Vision Approach</FONT></p>
                
                <p ALIGN="justify"><strong>Abstract:</strong> X-ray testing for baggage inspection has been increasingly used at airports, reducing the risk of terrorist crimes and attacks. Nevertheless, this task is still being carried out by human inspectors and with limited technological support. The technology that is being used is not always effective, as it depends mainly on the position of the object of interest, occlusion, and the accumulated experience of the inspector. Due to this problem, we have developed an approach that inspects X-ray images using active vision in order to automatically detect objects that represent a threat. Our method includes three steps: detection of potential threat objects in single views based on the similarity of features and spatial distribution; estimation of the best-next-viewusing Q-learning; and elimination of false alarms based on multiple view constraints. We tested our algorithm on X-ray images that included handguns and razor blades. In the detection of handguns we registered good results for recall and precision (Re = 67%, Pr = 83%) along with a high performance in the detection of razor blades (Re = 82%, Pr = 100%) taking into consideration 360 inspections in each case. Our results indicate that non-destructive inspection actively using X-ray images, leads to more effective object detection in complex environments, and helps to offset certain levels of occlusion and the internal disorder of baggage.</p>
                <div class="clear h20"></div>
                
                <div class="post_meta" style="margin-bottom:0";>
                <span>Download <a href="https://www.dropbox.com/s/l73j53tqyco8jo9/Example_Code_VRiffo2017.rar?dl=0">Example Code</a></span>
                </div>
                <div class="clear h20"></div>
                
                <div class="post_meta" style="margin-bottom:0";>
                	<span>May. 2017</span><span>DOI: <a href="https://link.springer.com/article/10.1007/s10921-017-0419-3">10.1007/s10921-017-0419-3</a></span><span><a href="Publications\Journals\PDF\Riffo2017_Springer_JNE.pdf">PDF</a></span><span><a href="Publications\Journals\BibTex\Riffo2017_Springer_JNE.txt">BibTeX</a></span><span>Published version: <a href="contact.html">Contact me</a></span><div class="clear"></div>
				</div>
        <!-- <a href="blog_post.html" class="more">More</a> -->
		
       </div>
       <div class="post" style="border-bottom-color:#CCC;"></div>
<!--&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& -->             
<!--&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& -->    
      <div class="half left"style="width:315; margin-bottom:0;">
            
                <div class="Image_Frame" style="margin-bottom:20;">
                    <img style="border:1px solid #CCC;" src="Publications\Journals\Images\SomeTrainingXrayImages.png" alt="Training Images" width="315" height="auto" >
                </div>
                
        <a style="font-size:14px;"href="http://www.ieeesmc.org/publications/transactions-on-smc-systems";>IEEE Transactions On Systems, Man, And Cybernetics: Systems</a>
        <p>Publisher: IEEE</p>
                
          <p>Authors:<br>
          D. Mery, E. Svec, M. Arias, <strong>V. Riffo</strong>, J. M. Saavedra, and S. Banerjee</p>
          
          <!--<a href="#" class="more">DETAIL</a> -->
      </div>    	
      
      
        <div class="half right" style="width:615; margin-bottom:0;>
                   
		<div class="post">
		  <p><FONT SIZE="3">Modern Computer Vision Techniques for X-Ray Testing in Baggage Inspection</FONT></p>
                
                <p ALIGN="justify"><strong>Abstract:</strong> X-ray screening systems have been used to safeguard environments in which access control is of paramount importance. Security checkpoints have been placed at the entrances to many public places to detect prohibited items, such as handguns and explosives. Generally, human operators are in charge of these tasks as automated recognition in baggage inspection is still far from perfect. Research and development on X-ray testing is, however, exploring new approaches based on computer vision that can be used to aid human operators. This paper attempts to make a contribution to the field of object recognition in X-ray testing by evaluating different computer vision strategies that have been proposed in the last years. We tested ten approaches. They are based on bag of words, sparse representations, deep learning, and classic pattern recognition schemes among others. For each method, we: 1) present a brief explanation; 2) show experimental results on the same database; and 3) provide concluding remarks discussing pros and cons of each method. In order to make fair comparisons, we define a common experimental protocol based on training, validation, and testing data (selected from the public GDXray database). The effectiveness of each method was tested in the recognition of three different threat objects: 1) handguns; 2) shuriken (ninja stars); and 3) razor blades. In our experiments, the highest recognition rate was achieved by methods based on visual vocabularies and deep features with more than 95% of accuracy. We strongly believe that it is possible to design an automated aid for the human inspection task using these computer vision algorithms.</p>
                <div class="clear h20"></div>
                
                <div class="post_meta" style="margin-bottom:0";>
                	<span>Apr. 2017</span><span>DOI: <a href="http://ieeexplore.ieee.org/document/7775025/">10.1109/TSMC.2016.2628381</a></span><span><a href="Publications\Journals\PDF\Mery2017_IEEE_SMCS.pdf">PDF</a></span><span><a href="Publications\Journals\BibTex\Mery2017_IEEE_SMCS.txt">BibTeX</a></span><span>Published version: <a href="contact.html">Contact me</a></span><div class="clear"></div>
				</div>
        <!-- <a href="blog_post.html" class="more">More</a> -->
		
        </div>
        <div class="post" style="border-bottom-color:#CCC;"></div>
<!--&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& --> 
 
<!--&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& -->    
      <div class="half left"style="width:315; margin-bottom:0;">
            
                <div class="Image_Frame" style="margin-bottom:20;">
                    <img style="border:1px solid #CCC;" src="Publications\Journals\Images\3Dclasification.png" alt="3D Clasification" width="315" height="auto" >
                </div>
                
        <a style="font-size:14px;"href="http://www.bindt.org/publications/insight-journal/";>Insight - Non-Destructive Testing & Condition Monitoring</a>
        <p>Publisher: The British Institute Of Non-Destructive Testing</p>
                
        <p>Authors:<br>
          D. Mery, <strong>V. Riffo</strong>, I. Zuccar, and C. Pieringer</p>
          
          <!--<a href="#" class="more">DETAIL</a> -->
      </div>    	
      
      
        <div class="half right" style="width:615; margin-bottom:0;>
                   
		<div class="post">
		  <p><FONT SIZE="3">Object Recognition in X-Ray Testing Using an Efficient Search Algorithm in Multiple Views</FONT></p>
                
                <p ALIGN="justify"><strong>Abstract:</strong> In order to reduce the security risk of commercial aircraft, passengers are not allowed to take certain items in their carry-on baggage. For this reason, human operators are trained to detect prohibited items using a manually-controlled baggage screening process. In this paper, the use of an automated method based on multiple X-ray views is proposed to recognise certain regular objects with highly-defined shapes and sizes. The method consists of two steps: ‚Äòmonocular analysis‚Äô, to obtain possible detections in each view of a sequence, and ‚Äòmultiple view analysis‚Äô, to recognise the objects of interest using matching in all views. The search for matching candidates is efficiently performed using a look-up table that is computed offline. In order to illustrate the effectiveness of the proposed method, experimental results on recognising regular objects (clips, springs and razor blades) in pencil cases are shown achieving high precision and recall (Pr = 95.7% , Re = 92.5%) for 120 objects. We believe that it would be possible to design an automated aid in a target detection task using the proposed algorithm.</p>
                <div class="clear h20"></div>
                
                <div class="post_meta" style="margin-bottom:0";>
                	<span>Feb. 2017</span><span>DOI: <a href="http://www.ingentaconnect.com/content/bindt/insight/2017/00000059/00000002/art00008">10.1784/insi.2017.59.2.85</a></span><span><a href="Publications\Journals\PDF\Mery2017_Insight.pdf">PDF</a></span><span><a href="Publications\Journals\BibTex\Mery2017_Insight.txt">BibTeX</a></span><span>Published version: <a href="contact.html">Contact me</a></span><div class="clear"></div>
				</div>
        <!-- <a href="blog_post.html" class="more">More</a> -->
		
        </div>
        <div class="post" style="border-bottom-color:#CCC;"></div>
<!--&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& -->
 
<!--&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& -->    
      <div class="half left"style="width:315; margin-bottom:0;">
            
                <div class="Image_Frame" style="margin-bottom:20;">
                    <img style="border:1px solid #CCC;" src="Publications\Journals\Images\AISMdetection.png" alt="Training Images" width="315" height="auto" >
                </div>
                
        <a style="font-size:14px;"href="http://www.ieeesmc.org/publications/transactions-on-smc-systems";>IEEE Transactions On Systems, Man, And Cybernetics: Systems</a>
        <p>Publisher: IEEE</p>
                
          <p>Authors:<br>
          <strong>V. Riffo</strong>, and D. Mery</p>
          
          <!--<a href="#" class="more">DETAIL</a> -->
      </div>    	
      
      
        <div class="half right" style="width:615; margin-bottom:0;>
                   
		<div class="post">
		  <p><FONT SIZE="3">Automated Detection of Threat Objects Using Adapted Implicit Shape Model</FONT></p>
                
                <p ALIGN="justify"><strong>Abstract:</strong> Baggage inspection using X-ray screening is a priority task that reduces the risk of crime and terrorist attacks. Manual detection of threat items is tedious because very few bags actually contain threat items and the process requires a high degree of concentration. An automated solution would be a welcome development in this field. We propose a methodology for automatic detection of threat objects using single X-ray images. Our approach is an adaptation of a methodology originally created for recognizing objects in photographs based on implicit shape models. Our detection method uses a visual vocabulary and an occurrence structure generated from a training dataset that contains representative X-ray images of the threat object to be detected. Our method can be applied to single views of grayscale X-ray images obtained using a single energy acquisition system. We tested the effectiveness of our method for the detection of three different threat objects: 1) razor blades; 2) shuriken (ninja stars); and 3) handguns. The testing dataset for each threat object consisted of 200 X-ray images of bags. The true positive and false positive rates (TPR and FPR) are: (0.99 and 0.02) for razor blades, (0.97 and 0.06) for shuriken, and (0.89 and 0.18) for handguns. If other representative training datasets were utilized, we believe that our methodology could aid in the detection of other kinds of threat objects.</p>
                <div class="clear h20"></div>
                
                <div class="post_meta" style="margin-bottom:0";>
                <span>Download <a href="https://www.dropbox.com/s/75ckpzkov78bepd/AISM%20Example%20Code.rar?dl=0">Example Code</a></span>
                </div>
                <div class="clear h20"></div>
                
                <div class="post_meta" style="margin-bottom:0";>
                	<span>Apr. 2016</span><span>DOI: <a href="http://ieeexplore.ieee.org/document/7123190/">10.1109/TSMC.2015.2439233</a></span><span><a href="Publications\Journals\PDF\Riffo2016_IEEE_SMCS.pdf">PDF</a></span><span><a href="Publications\Journals\BibTex\Riffo2016_IEEE_SMCS.txt">BibTeX</a></span><span>Published version: <a href="contact.html">Contact me</a></span><div class="clear"></div>
				</div>
        <!-- <a href="blog_post.html" class="more">More</a> -->
		
        </div>
        <div class="post" style="border-bottom-color:#CCC;"></div>
<!--&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& -->  

<!--&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& -->    
      <div class="half left"style="width:315; margin-bottom:0;">
            
                <div class="Image_Frame" style="margin-bottom:20;">
                    <img style="border:1px solid #CCC;" src="Publications\Journals\Images\GDX_Random_small.png" alt="Geometric Model" width="315" height="auto" >
                </div>
                
                <a style="font-size:14px;"href="https://link.springer.com/journal/10921";>Journal Of Nondestructive Evaluation</a>
        <p>Publisher: Springer</p>
                
          <p>Authors:<br>
          D. Mery, <strong>V. Riffo</strong>, U. Zscherpel, G. Mondrag√≥n, I. Lillo, I. Zuccar, H. Lobel, and M. Carrasco</p>
          
          <!--<a href="#" class="more">DETAIL</a> -->
        </div>    	
      
      
        <div class="half right" style="width:615; margin-bottom:0;>
                   
		<div class="post">
		  <p><FONT SIZE="3">GDXray: The Database of X-ray Images for Nondestructive
Testing</FONT></p>
                
                <p ALIGN="justify"><strong>Abstract:</strong> In this paper, we present a new dataset consisting of 19,407 X-ray images. The images are organized in a public database called GDXray that can be used free of charge, but for research and educational purposes only. The database includes five groups of X-ray images: castings, welds, baggage, natural objects and settings. Each group has several series, and each series several X-ray images. Most of the series are annotated or labeled. In such cases, the coordinates of the bounding boxes of the objects of interest or the labels of the images are available in standard text files. The size of GDXray is 3.5 GB and it can be downloaded from our website. We believe that GDXray represents a relevant contribution to the X-ray testing community. On the one hand, students, researchers and engineers can use these X-ray images to develop, test and evaluate image analysis and computer vision algorithms without purchasing expensive X-ray equipment. On the other hand, these images can be used as a benchmark in order to test and compare the performance of different approaches on the same data. Moreover, the database can be used in the training programs of human inspectors.</p>
                <div class="clear h20"></div>
                
                <div class="post_meta" style="margin-bottom:0";>
                	<span>Nov. 2015</span><span>DOI: <a href="https://link.springer.com/article/10.1007/s10921-015-0315-7">10.1007/s10921-015-0315-7</a></span><span><a href="Publications\Journals\PDF\GDXray2015.pdf">PDF</a></span><span><a href="Publications\Journals\BibTex\GDXray2015.txt">BibTeX</a></span><span>Published version: <a href="contact.html">Contact me</a></span><div class="clear"></div>
				</div>
        <!-- <a href="blog_post.html" class="more">More</a> -->
		
       </div>
       <div class="post" style="border-bottom-color:#CCC;"></div>
<!--&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& --> 

<!--&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& -->    
      <div class="half left"style="width:315; margin-bottom:0;">
            
                <div class="Image_Frame" style="margin-bottom:20;">
                    <img style="border:1px solid #CCC;" src="Publications\Journals\Images\GunSequence1.png" alt="Geometric Model" width="315" height="auto" >
                </div>
                
                <a style="font-size:14px;"href="https://www.asnt.org/me";>Materials Evaluation</a>
        <p>Publisher: The American Society for Nondestructive Testing</p>
                
          <p>Authors:<br>
          D. Mery, and <strong>V. Riffo</strong></p>
          
          <!--<a href="#" class="more">DETAIL</a> -->
        </div>    	
      
      
        <div class="half right" style="width:615; margin-bottom:0;>
                   
		<div class="post">
		  <p><FONT SIZE="3">Automated Object Recognition Using Multiple X-ray Views</FONT></p>
                
                <p ALIGN="justify"><strong>Abstract:</strong> In order to reduce the security risk of a commercial aircraft, passengers are not allowed to take certain items in their carry-on baggage. For this reason, human operators are trained to detect prohibited items using a manually controlled baggage screening process. The inspection process, however, is highly complex as hazardous items are very difficult to detect when placed in close packed bags, superimposed by other objects, and/or rotated showing an unrecognizable profile. In this paper, the authors review certain advances achieved by their research group in this field. Their methodology is based on multiple view analysis, because it can be a powerful tool for examining complex objects in cases in which uncertainty can lead to misinterpretation. In their approach, multiple views (taken from fixed points of view, or using an active vision approach in which the best views are automated selected) are analyzed in the detection of regular objects. In order to illustrate the effectiveness of the proposed method, experimental results on recognizing guns, razor blades, pins, clips, and springs in baggage inspection are presented achieving approximately 90% accuracy. The authors believe that it would be possible to design an automated aid in a target detection task using the proposed algorithm.<br>Editor's Note: This paper is reprinted with permission of the British Institute of Non-Destructive Testing. An earlier version was presented at the 52nd Annual Conference of the British Institute of Non-Destructive Testing, in Telford, England, September 2013 and a paper, "Detection of Regular Objects in Baggage using Multiple X-ray Views," by the authors and two co-authors appeared in Insight Non-Destructive Testing and Condition Monitoring, Vol. 55, No. 1, January 2013, pp. 16-20(5). Some additions and edits have been made since by the authors.</p>
                <div class="clear h20"></div>
                
                <div class="post_meta" style="margin-bottom:0";>
                	<span>Nov. 2014</span><span>DOI: <a href="https://ndtlibrary.asnt.org/2014/AutomatedObjectRecognitionusingMultipleXrayViews">without DOI</a></span><span><a href="Publications\Journals\PDF\Mery2014_MaterEval.pdf">PDF</a></span><span><a href="Publications\Journals\BibTex\Mery2014_MaterEval.txt">BibTeX</a></span><span>Published version: <a href="contact.html">Contact me</a></span><div class="clear"></div>
				</div>
        <!-- <a href="blog_post.html" class="more">More</a> -->
		
       </div>
       <div class="post" style="border-bottom-color:#CCC;"></div>
<!--&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& -->

<!--&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& -->    
      <div class="half left"style="width:315; margin-bottom:0;">
            
                <div class="Image_Frame" style="margin-bottom:20;">
                    <img style="border:1px solid #CCC;" src="Publications\Journals\Images\RazorBladeSequence.png" alt="3D Clasification" width="315" height="auto" >
                </div>
                
        <a style="font-size:14px;"href="http://www.bindt.org/publications/insight-journal/";>Insight - Non-Destructive Testing & Condition Monitoring</a>
        <p>Publisher: The British Institute Of Non-Destructive Testing</p>
                
        <p>Authors:<br>
          D. Mery, G. Mondragon, <strong>V. Riffo</strong>, and I. Zuccar</p>
          
          <!--<a href="#" class="more">DETAIL</a> -->
      </div>    	
      
      
        <div class="half right" style="width:615; margin-bottom:0;>
                   
		<div class="post">
		  <p><FONT SIZE="3">Detection of Regular Objects in Baggage Using Multiple X-Ray Views</FONT></p>
                
                <p ALIGN="justify"><strong>Abstract:</strong> In order to reduce the security risk of a commercial aircraft, passengers are not allowed to take certain items in carry-on baggage. For this reason, human operators are trained to detect prohibited items using a manually controlled baggage screening process. In this paper, we propose the use of a method based on multiple X-ray views to detect some regular prohibited items with very defined shapes and sizes. The method consists of two steps: 'structure estimation', to obtain a geometric model of the multiple views from the object to be inspected (baggage); and 'parts detection', to detect the parts of interest (prohibited items). The geometric model is estimated using a structure from a motion algorithm. The detection of the parts of interest is performed by an ad-hoc segmentation algorithm (object dependent) followed by a general tracking algorithm based on geometric and appearance constraints. In order to illustrate the effectiveness of the proposed method, experimental results on detecting regular objects ‚Äì razor blades and guns ‚Äì are shown yielding promising results. </p>
                <div class="clear h20"></div>
                
                <div class="post_meta" style="margin-bottom:0";>
                	<span>Jan. 2013</span><span>DOI: <a href="http://www.ingentaconnect.com/content/bindt/insight/2013/00000055/00000001/art00004">10.1784/insi.2012.55.1.16</a></span><span><a href="Publications\Journals\PDF\Mery2013_Insight.pdf">PDF</a></span><span><a href="Publications\Journals\BibTex\Mery2013_Insight.txt">BibTeX</a></span><span>Published version: <a href="contact.html">Contact me</a></span>
                	<div class="clear"></div>
				</div>
        <!-- <a href="blog_post.html" class="more">More</a> -->
		
        </div>
        <div class="post" style="border-bottom-color:#CCC;"></div>
<!--&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& -->

<!--&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& -->    
      <div class="half left"style="width:315; margin-bottom:0;">
            
                <div class="Image_Frame" style="margin-bottom:20;">
                    <img style="border:1px solid #CCC;" src="Publications\Journals\Images\SERobot_Obj9_sec2.jpg" alt="3D Clasification" width="315" height="auto" >
                </div>
                
        <a style="font-size:14px;"href="http://www.bindt.org/publications/insight-journal/";>Insight - Non-Destructive Testing & Condition Monitoring</a>
        <p>Publisher: The British Institute Of Non-Destructive Testing</p>
                
        <p>Authors:<br>
          <strong>V. Riffo</strong>, and D. Mery</p>
          
          <!--<a href="#" class="more">DETAIL</a> -->
      </div>    	
      
      
        <div class="half right" style="width:615; margin-bottom:0;>
                   
		<div class="post">
		  <p><FONT SIZE="3">Active X-Ray Testing of Complex Objects</FONT></p>
                
                <p ALIGN="justify"><strong>Abstract:</strong> X-ray testing of complex objects ‚Äì such as luggage screening at airports ‚Äì is usually performed manually. This is not always effective, since it depends strongly on the pose of the objects of interest (target objects) and occlusion, as well as human capabilities. Additionally, certain target objects are difficult to detect using only one viewpoint. For this reason, we have developed an active X-ray testing framework that is able to find an adequate viewpoint of the target object in order to obtain better X-ray images to analyse. The key idea of our method is to adapt automatically the viewpoint of the X-ray images in order to project the target object in poses where the detection performance should be higher. Thus, the detection inside complex objects can be performed in a more effective way. Using a robotic arm and a semi- automatic manipulator system, the robustness and reliability of the method have been verified in the automated detection of razor blades located inside nine different objects, showing promising preliminary results: in 130 experiments we were able to detect the razor blade 115 times with 10 false alarms, achieving a recall of 89% and a precision of 92%.</p>
                <div class="clear h20"></div>
                
                <div class="post_meta" style="margin-bottom:0";>
                	<span>Jan. 2012</span><span>DOI: <a href="http://www.ingentaconnect.com/content/bindt/insight/2012/00000054/00000001/art00008">10.1784/insi.2012.54.1.28</a></span><span><a href="Publications\Journals\PDF\Riffo2012_Insight.pdf">PDF</a></span><span><a href="Publications\Journals\BibTex\Riffo2012_Insight.txt">BibTeX</a></span><span>Published version: <a href="contact.html">Contact me</a></span>
                	<div class="clear"></div>
				</div>
        <!-- <a href="blog_post.html" class="more">More</a> -->
		
        </div>
        <div class="post" style="border-bottom-color:#CCC;"></div>
<!--&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& -->

<!--&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& -->    
      <div class="half left"style="width:315; margin-bottom:0;">
            
                <div class="Image_Frame" style="margin-bottom:20;">
                    <img style="border:1px solid #CCC;" src="Publications\Journals\Images\FishBoneDetection.png" alt="Geometric Model" width="315" height="auto" >
                </div>
                
                <a style="font-size:14px;"href="https://www.journals.elsevier.com/journal-of-food-engineering";>Journal Of Food Engineering</a>
                <p>Publisher: Elsevier</p>
                
          <p>Authors:<br>
          D. Mery, I. Lillo, H. Loebel, <strong>V. Riffo</strong>, A. Soto, A.Cipriano, and J.M. Aguilera</p>
          
          <!--<a href="#" class="more">DETAIL</a> -->
        </div>    	
      
      
        <div class="half right" style="width:615; margin-bottom:0;>
                   
		<div class="post">
		  <p><FONT SIZE="3">Automated Fish Bone Detection Using X-Ray Imaging
</FONT></p>
                
                <p ALIGN="justify"><strong>Abstract:</strong> In countries where fish is often consumed, fish bones are some of the most frequently ingested foreign bodies encountered in foods. In the production of fish fillets, fish bone detection is performed by human inspection using their sense of touch and vision which can lead to misclassification. Effective detection of fish bones in the quality control process would help avoid this problem. For this reason, an X-ray machine vision approach to automatically detect fish bones in fish fillets was developed. This paper describes our approach and the corresponding experiments with salmon and trout fillets. In the experiments, salmon X-ray images using 10 x 10 pixels detection windows and 24 intensity features (selected from 279 features) were analyzed. The methodology was validated using representative fish bones and trouts provided by a salmon industry and yielded a detection performance of 99%. We believe that the proposed approach opens new possibilities in the field of automated visual inspection of salmon, trout and other similar fish.</p>
                <div class="clear h20"></div>
                
                <div class="post_meta" style="margin-bottom:0";>
                	<span>Aug. 2011</span><span>DOI: <a href="http://www.sciencedirect.com/science/article/pii/S0260877411001324">10.1016/j.jfoodeng.2011.03.007</a></span><span><a href="Publications\Journals\PDF\Mery2011_JFoodEng.pdf">PDF</a></span><span><a href="Publications\Journals\BibTex\Mery2011_JFoodEng.txt">BibTeX</a></span><span>Published version: <a href="contact.html">Contact me</a></span>
                	<div class="clear"></div>
				</div>
        <!-- <a href="blog_post.html" class="more">More</a> -->
		
        </div>
        <div class="post" style="border-bottom-color:#CCC;"></div>
<!--&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& -->
<!--&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& -->



<!--<div class="pagging">
     <ul>
        <li><a href="#">Previous</a></li>
        <li><a href="#">1</a></li>
        <li><a href="#">2</a></li>
        <li><a href="#">3</a></li>
        <li><a href="#">4</a></li>
        <li><a href="#">5</a></li>
        <li><a href="#">6</a></li>
        <li><a href="#">7</a></li>
        <li><a href="#">8</a></li>
        <li><a href="#">Next</a></li>
     </ul>
</div> -->
		
        
<!--        <div id="sidebar" class="right">
        	<div class="sidebar_box">
            <h3>Categories</h3>
            <div class="sidebar_box_content">
                <ul class="list_bullet">
                    <li>Integer placerat dolor vel</li>
                    <li>Condimentum vulputate augue</li>
                    <li>Felis pharetra felis sed</li>
                    <li>Tortor mi in massa donec</li>
                    <li>Dolor vel condimentum</li>
                    <li>Augue felis pharetra felis sed</li>
                    <li>Vulputate tortor mi in massa</li>
                </ul>
            </div>
		</div>
        <div class="sidebar_box">
            <h3>Popular Posts</h3>
            <div class="sidebar_box_content">
                <ul class="no_bullet">
                    <li>
                        <a href="#" class="header">Etiam suscipit bibendum scelerisque</a>
                        Etiam faucibus aliquet turpis sit amet congue rutrum blandit dui quis condimentum.
                    </li>
                    <li>
                        <a href="#" class="header">Praesent euismod mi dictum tempus</a>
                        Aenean rutrum, velit in tincidunt ullamcorper, augue arcu cursus tortor.
                    </li>
                    <li>
                        <a href="#" class="header">Nunc bibendum cursus justo</a>
                        Sed quam felis, aliquam non tempor quis lacus odio at rutrum accumsan.
                    </li>
                    <li>
                        <a href="#" class="header">In pretium libero ut libero molestie</a>
                        Imperdiet urna orci sit amet velit massa sit amet enim pulvinar molestie.
                    </li>
                </ul>
			</div>
		</div>
        </div>         -->
        
        
        <div class="clear"></div>
    </div><!-- END of templatemo_main -->
</div><!-- END of templatemo_wrapper -->

<!--&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& -->
<div id="templatemo_bottom_wrapper">
	<div id="templatemo_bottom">
    	<div class="col one_fourth">
            <h4>Useful Links</h4>
            <p>
             <span class="header"><strong>Academics:</strong></span>
             <a href="http://dmery.ing.puc.cl/">Domingo Mery</a>
             <br>
             <a href="http://www.robots.ox.ac.uk/~az/">Andrew Zisserman</a>
             <br>
             <a href="http://axiom.anu.edu.au/~hartley/">Richard Hartley</a>
             <br>
             <a href="http://www.andrewng.org/">Andrew Ng</a>
             <br>
            </p>
        </div>
        
        <div class="col one_fourth">
        </div>

         
    	<div class="col one_fourth">
    	<h4>Contact Information</h4>
        <ul class="no_bullet">
            <li>
                <span class="header"><strong>Address:</strong></span>
            Universidad de Atacama,<br>
            Av. Copayapu N¬∞ 485,<br>
            Regi√≥n de Atacama, <br>
            Copiap√≥-Chile.
            <li>
                <span class="header"><strong>E-mail:</strong></span>
<!--            vladimir.riffo.b@gmail.com<br> -->
            vladimir.riffo@uda.cl<br>
<!--            vriffo1@uc.cl -->
            </li>
            <li>
                <span class="header"><strong>Phone:</strong></span>
            (+56) 52 225-5685
            </li>            
<!--                <li>
                <span class="header"><a href="#">Sed vel justo ut sodales nulla</a></span>
                Duis posuere ipsum quis arcu gravida  tincidunt eget ante gravid eu odio.
            </li> -->
		</ul>
    </div>
    <div class="col one_fourth no_margin_right">
    	<h4>Follow Me</h4>
        <ul class="no_bullet">
        	<a href="https://scholar.google.com.au/citations?user=ElatKQgAAAAJ&hl=en"><img src="images/iconScholar.png" alt="Scholar" width="24" height="24" title="scholar" /></a>
            <a href="https://www.linkedin.com/in/vladimir-riffo-3473922a/n"><img src="images/icoLinkedin.png" alt="Linkedin" width="24" height="24" title="linkedin" /></a>
            <a href="https://www.facebook.com"><img src="images/icoFacebook.png" alt="Facebook" width="24" height="24" title="facebook" /></a> 
            <a href="http://www.flickr.com/photos/vladimir_riffo/"><img src="images/icoFlickr.png" alt="Flickr" width="24" height="24" title="flickr" /></a>
            <a href="https://www.youtube.com/watch?v=giTDwM6bsDU"><img src="images/icoYoutube.png" alt="Youtube" width="24" height="24" title="youtube" /></a>
<!--            <a href="http://vriffo1.sitios.ing.uc.cl/index.html"><img src="images/icon-www.png" alt="Old website" width="24" height="24" title="old website" /></a>
 -->
            <p>Old version of this <a href="http://vriffo1.sitios.ing.uc.cl/index.html">website</a></p>

        </ul>
    </div>
        
        <div class="clear"></div>
    </div><!-- END of templatemo_bottom -->
    </div><!-- END of templatemo_bottom_wrapper -->    
<div id="templatemo_footer_wrapper">    
    <div id="templatemo_footer">
    	<p>Copyright ¬© 2017 <a href="#">Vladimir Riffo</a></p>
    </div><!-- END of templatemo_footer -->
</div><!-- END of templatemo_footer_wrapper -->

</html>